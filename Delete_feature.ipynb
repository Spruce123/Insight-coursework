{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "bitcoin_market_info = pd.read_csv(\"combined.csv\")\n",
    "bitcoin_market_info.head()\n",
    "model_data = bitcoin_market_info\n",
    "\n",
    "split_date = '2017-06-01'\n",
    "training_set, test_set = model_data[model_data['date']<split_date], model_data[model_data['date']>=split_date]\n",
    "training_set = training_set.drop('date', 1)\n",
    "training_set = training_set.drop('day', 1)\n",
    "test_set = test_set.drop('date', 1)\n",
    "test_set = test_set.drop('day', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            price    difficulty  recipients  num_tranc\n",
      "0        0.000000  1.000000e+00           0       14.0\n",
      "1        0.000000  1.000000e+00           0      106.0\n",
      "2        0.000000  1.000000e+00           0      116.0\n",
      "3        0.000000  1.000000e+00           0      136.0\n",
      "4        0.000000  1.000000e+00           0      109.0\n",
      "5        0.000000  1.000000e+00           1      120.0\n",
      "6        0.000000  1.000000e+00           0      115.0\n",
      "7        0.000000  1.000000e+00           1       68.0\n",
      "8        0.000000  1.000000e+00           0      195.0\n",
      "9        0.000000  1.000000e+00           0      105.0\n",
      "10       0.000000  1.000000e+00           1      122.0\n",
      "11       0.000000  1.000000e+00           1      129.0\n",
      "12       0.000000  1.000000e+00           1      127.0\n",
      "13       0.000000  1.000000e+00           0      126.0\n",
      "14       0.000000  1.000000e+00           0      129.0\n",
      "15       0.000000  1.000000e+00           1      135.0\n",
      "16       0.000000  1.000000e+00           0      127.0\n",
      "17       0.000000  1.000000e+00           0      119.0\n",
      "18       0.000000  1.000000e+00           0      141.0\n",
      "19       0.000000  1.000000e+00           1      123.0\n",
      "20       0.000000  1.000000e+00           0      124.0\n",
      "21       0.000000  1.000000e+00           0      129.0\n",
      "22       0.000000  1.000000e+00           1      125.0\n",
      "23       0.000000  1.000000e+00           0      111.0\n",
      "24       0.000000  1.000000e+00           0       96.0\n",
      "25       0.000000  1.000000e+00           1      103.0\n",
      "26       0.000000  1.000000e+00           0      104.0\n",
      "27       0.000000  1.000000e+00           1      106.0\n",
      "28       0.000000  1.000000e+00           0      119.0\n",
      "29       0.000000  1.000000e+00           1      115.0\n",
      "...           ...           ...         ...        ...\n",
      "1503  1141.813000  4.996359e+11      563978   288141.0\n",
      "1504  1133.079314  4.996359e+11      577210   316555.0\n",
      "1505  1190.454250  4.996359e+11      542024   295463.0\n",
      "1506  1208.800500  4.996359e+11      489502   238286.0\n",
      "1507  1226.617037  4.996359e+11      582092   307893.0\n",
      "1508  1180.023713  5.178079e+11      449517   228679.0\n",
      "1509  1184.880671  5.208087e+11      520807   271976.0\n",
      "1510  1205.634875  5.208087e+11      469185   245184.0\n",
      "1511  1217.930087  5.208087e+11      566240   310104.0\n",
      "1512  1258.361412  5.208087e+11      612624   330354.0\n",
      "1513  1257.988112  5.208087e+11      489969   245039.0\n",
      "1514  1279.414687  5.208087e+11      580192   325387.0\n",
      "1515  1345.353912  5.218397e+11      554683   297884.0\n",
      "1516  1334.979038  5.219745e+11      633998   341319.0\n",
      "1517  1417.172812  5.219745e+11      542813   294786.0\n",
      "1518  1507.576857  5.219745e+11      547216   295149.0\n",
      "1519  1533.335071  5.219745e+11      523627   267193.0\n",
      "1520  1535.868429  5.219745e+11      581353   316011.0\n",
      "1521  1721.284971  5.219745e+11      621141   332879.0\n",
      "1522  1820.990562  5.599709e+11      568511   294743.0\n",
      "1523  1771.920012  5.599709e+11      623280   329266.0\n",
      "1524  1723.126937  5.599709e+11      636226   329229.0\n",
      "1525  1807.485062  5.599709e+11      591507   317527.0\n",
      "1526  1961.520487  5.599709e+11      633590   319502.0\n",
      "1527  2046.534463  5.599709e+11      608712   326057.0\n",
      "1528  2287.710288  5.841522e+11      687285   367710.0\n",
      "1529  2387.206286  5.959219e+11      659051   350114.0\n",
      "1530  2014.052962  5.959219e+11      651456   331914.0\n",
      "1531  2275.930700  5.959219e+11      594350   321638.0\n",
      "1532  2285.933914  5.959219e+11      614065   321634.0\n",
      "\n",
      "[1533 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(inputs)\n",
    "LSTM_training_outputs = preprocessing.scale(training_set[\"price\"])\n",
    "LSTM_training_outputs  = LSTM_training_outputs[10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input(inputs):\n",
    "    result = []\n",
    "    for i in range(0,len(inputs)-10):\n",
    "        input_ = []\n",
    "        #print(input_)\n",
    "        for p in range(10):\n",
    "            index = i + 1 + p\n",
    "            input_.append(inputs[index])\n",
    "        input_ = np.array(input_)\n",
    "        result.append(input_) \n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  if sys.path[0] == '':\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  app.launch_new_instance()\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:18: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n"
     ]
    }
   ],
   "source": [
    "window_len = 10\n",
    "norm_cols = [\"difficulty\",\"price\",\"recipients\",\"num_tranc\"]\n",
    "# 1 remove difficulty\n",
    "# 2 remove price\n",
    "# 3 remove recipients\n",
    "# 4 remove num_tranc\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "inputs_1 = preprocessing.scale(training_set.drop(\"difficulty\",1))\n",
    "inputs_1 = get_input(inputs_1.tolist())\n",
    "inputs_2 = preprocessing.scale(training_set.drop(\"price\",1))\n",
    "inputs_2 = get_input(inputs_2.tolist())\n",
    "inputs_3 = preprocessing.scale(training_set.drop(\"recipients\",1))\n",
    "inputs_3 = get_input(inputs_3.tolist())\n",
    "inputs_4 = preprocessing.scale(training_set.drop(\"num_tranc\",1))\n",
    "inputs_4 = get_input(inputs_4.tolist())\n",
    "inputs_5 = preprocessing.scale(training_set)\n",
    "inputs_5 = get_input(inputs_5.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1523\n"
     ]
    }
   ],
   "source": [
    "print(len(inputs_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1523\n"
     ]
    }
   ],
   "source": [
    "print(len(LSTM_training_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:176: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:176: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  import sys\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:176: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  if __name__ == '__main__':\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:176: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    }
   ],
   "source": [
    "tinputs_1 = preprocessing.scale(test_set.drop(\"difficulty\",1))\n",
    "tinputs_1 = get_input(tinputs_1.tolist())\n",
    "tinputs_2 = preprocessing.scale(test_set.drop(\"price\",1))\n",
    "tinputs_2 = get_input(tinputs_2.tolist())\n",
    "tinputs_3 = preprocessing.scale(test_set.drop(\"recipients\",1))\n",
    "tinputs_3 = get_input(tinputs_3.tolist())\n",
    "tinputs_4 = preprocessing.scale(test_set.drop(\"num_tranc\",1))\n",
    "tinputs_4 = get_input(tinputs_4.tolist())\n",
    "tinputs_5 = preprocessing.scale(test_set)\n",
    "tinputs_5 = get_input(tinputs_5.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "\n",
    "def build_model(inputs, output_size, neurons, activ_func=\"linear\",\n",
    "                dropout=0.25, loss=\"mae\", optimizer=\"adam\"):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(LSTM(neurons, input_shape=(inputs.shape[1], inputs.shape[2])))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(units=output_size))\n",
    "    model.add(Activation(activ_func))\n",
    "\n",
    "    model.compile(loss=loss, optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " - 25s - loss: 0.1747\n",
      "Epoch 2/50\n",
      " - 23s - loss: 0.1194\n",
      "Epoch 3/50\n",
      " - 24s - loss: 0.1030\n",
      "Epoch 4/50\n",
      " - 23s - loss: 0.1036\n",
      "Epoch 5/50\n",
      " - 23s - loss: 0.0982\n",
      "Epoch 6/50\n",
      " - 22s - loss: 0.0933\n",
      "Epoch 7/50\n",
      " - 22s - loss: 0.0920\n",
      "Epoch 8/50\n",
      " - 21s - loss: 0.0889\n",
      "Epoch 9/50\n",
      " - 22s - loss: 0.0930\n",
      "Epoch 10/50\n",
      " - 22s - loss: 0.0916\n",
      "Epoch 11/50\n",
      " - 22s - loss: 0.0906\n",
      "Epoch 12/50\n",
      " - 22s - loss: 0.0893\n",
      "Epoch 13/50\n",
      " - 23s - loss: 0.0846\n",
      "Epoch 14/50\n",
      " - 22s - loss: 0.0835\n",
      "Epoch 15/50\n",
      " - 23s - loss: 0.0839\n",
      "Epoch 16/50\n",
      " - 23s - loss: 0.0844\n",
      "Epoch 17/50\n",
      " - 23s - loss: 0.0869\n",
      "Epoch 18/50\n",
      " - 22s - loss: 0.0828\n",
      "Epoch 19/50\n",
      " - 21s - loss: 0.0857\n",
      "Epoch 20/50\n",
      " - 23s - loss: 0.0798\n",
      "Epoch 21/50\n",
      " - 23s - loss: 0.0837\n",
      "Epoch 22/50\n",
      " - 23s - loss: 0.0804\n",
      "Epoch 23/50\n",
      " - 23s - loss: 0.0843\n",
      "Epoch 24/50\n",
      " - 23s - loss: 0.0841\n",
      "Epoch 25/50\n",
      " - 23s - loss: 0.0824\n",
      "Epoch 26/50\n",
      " - 23s - loss: 0.0838\n",
      "Epoch 27/50\n",
      " - 23s - loss: 0.0829\n",
      "Epoch 28/50\n",
      " - 22s - loss: 0.0809\n",
      "Epoch 29/50\n",
      " - 22s - loss: 0.0803\n",
      "Epoch 30/50\n",
      " - 23s - loss: 0.0787\n",
      "Epoch 31/50\n",
      " - 23s - loss: 0.0772\n",
      "Epoch 32/50\n",
      " - 22s - loss: 0.0786\n",
      "Epoch 33/50\n",
      " - 23s - loss: 0.0797\n",
      "Epoch 34/50\n",
      " - 22s - loss: 0.0816\n",
      "Epoch 35/50\n",
      " - 22s - loss: 0.0814\n",
      "Epoch 36/50\n",
      " - 22s - loss: 0.0757\n",
      "Epoch 37/50\n",
      " - 22s - loss: 0.0827\n",
      "Epoch 38/50\n",
      " - 22s - loss: 0.0833\n",
      "Epoch 39/50\n",
      " - 22s - loss: 0.0812\n",
      "Epoch 40/50\n",
      " - 22s - loss: 0.0809\n",
      "Epoch 41/50\n",
      " - 23s - loss: 0.0785\n",
      "Epoch 42/50\n",
      " - 21s - loss: 0.0784\n",
      "Epoch 43/50\n",
      " - 22s - loss: 0.0806\n",
      "Epoch 44/50\n",
      " - 22s - loss: 0.0755\n",
      "Epoch 45/50\n",
      " - 21s - loss: 0.0844\n",
      "Epoch 46/50\n",
      " - 22s - loss: 0.0791\n",
      "Epoch 47/50\n",
      " - 22s - loss: 0.0827\n",
      "Epoch 48/50\n",
      " - 22s - loss: 0.0793\n",
      "Epoch 49/50\n",
      " - 22s - loss: 0.0766\n",
      "Epoch 50/50\n",
      " - 22s - loss: 0.0773\n",
      "Epoch 1/50\n",
      "Epoch 2/50\n",
      "Epoch 3/50\n",
      "Epoch 4/50\n",
      "Epoch 5/50\n",
      "Epoch 6/50\n",
      "Epoch 7/50\n",
      "Epoch 8/50\n",
      "Epoch 9/50\n",
      "Epoch 10/50\n",
      "Epoch 11/50\n",
      "Epoch 12/50\n",
      "Epoch 13/50\n",
      "Epoch 14/50\n",
      "Epoch 15/50\n",
      "Epoch 16/50\n",
      "Epoch 17/50\n",
      "Epoch 18/50\n",
      "Epoch 19/50\n",
      "Epoch 20/50\n",
      "Epoch 21/50\n",
      "Epoch 22/50\n",
      "Epoch 23/50\n",
      "Epoch 24/50\n",
      "Epoch 25/50\n",
      "Epoch 26/50\n",
      "Epoch 27/50\n",
      "Epoch 28/50\n",
      "Epoch 29/50\n",
      "Epoch 30/50\n",
      "Epoch 31/50\n",
      "Epoch 32/50\n",
      "Epoch 33/50\n",
      "Epoch 34/50\n",
      "Epoch 35/50\n",
      "Epoch 36/50\n",
      "Epoch 37/50\n",
      "Epoch 38/50\n",
      "Epoch 39/50\n",
      "Epoch 40/50\n",
      "Epoch 41/50\n",
      "Epoch 42/50\n",
      "Epoch 43/50\n",
      "Epoch 44/50\n",
      "Epoch 45/50\n",
      "Epoch 46/50\n",
      "Epoch 47/50\n",
      "Epoch 48/50\n",
      "Epoch 49/50\n",
      "Epoch 50/50\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(203)\n",
    "# eth_model_1 = build_model(inputs_1, output_size=1, neurons = 20)\n",
    "# eth1_history = eth_model_1.fit(inputs_1, LSTM_training_outputs, \n",
    "#                             epochs=50, batch_size=1,verbose=2, shuffle=True)\n",
    "# eth_model_2 = build_model(inputs_2, output_size=1, neurons = 20)\n",
    "# eth2_history = eth_model_2.fit(inputs_2, LSTM_training_outputs, \n",
    "#                             epochs=50, batch_size=1,verbose=2, shuffle=True)\n",
    "# eth_model_3 = build_model(inputs_3, output_size=1, neurons = 20)\n",
    "# eth3_history = eth_model_3.fit(inputs_3, LSTM_training_outputs, \n",
    "#                             epochs=50, batch_size=1,verbose=2, shuffle=True)\n",
    "eth_model_4 = build_model(inputs_4, output_size=1, neurons = 20)\n",
    "eth4_history = eth_model_4.fit(inputs_4, LSTM_training_outputs, \n",
    "                            epochs=50, batch_size=1,verbose=2, shuffle=True)\n",
    "eth_model_5 = build_model(inputs_5, output_size=1, neurons = 20)\n",
    "eth5_history = eth_model_5.fit(inputs_5, LSTM_training_outputs, \n",
    "                            epochs=50, batch_size=1,verbose=20, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax1 = plt.subplots(1,1)\n",
    "\n",
    "# ax1.plot(eth_history.epoch, eth_history.history['loss'])\n",
    "\n",
    "# #ax1.set_title('Training Error')\n",
    "\n",
    "# # if eth_model.loss == 'mae':\n",
    "# #     ax1.set_ylabel('Mean Absolute Error (MAE)',fontsize=12)\n",
    "# # # just in case you decided to change the model loss calculation\n",
    "# # else:\n",
    "# #     ax1.set_ylabel('Model Loss',fontsize=12)\n",
    "# # ax1.set_xlabel('# Epochs',fontsize=12)\n",
    "# plt.show()\n",
    "\n",
    "LSTM_test_outputs = preprocessing.scale(test_set[\"price\"])[10:]\n",
    "output4 = eth_model_4.predict(tinputs_4)\n",
    "# output1 = eth_model_1.predict(tinputs_1)\n",
    "# output2 = eth_model_2.predict(tinputs_2)\n",
    "# output3 = eth_model_3.predict(tinputs_3)\n",
    "\n",
    "#output5 = eth_model.predict(tinputs_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rmse(test_predict):\n",
    "    return np.sqrt(((LSTM_test_outputs - test_predict) ** 2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3903702761835828\n",
      "1.1678219975599458\n",
      "1.358654603396754\n",
      "1.311267787185434\n"
     ]
    }
   ],
   "source": [
    "rmse1 = get_rmse(output1)\n",
    "print(rmse1)\n",
    "rmse2 = get_rmse(output2)\n",
    "print(rmse2)\n",
    "rmse3 = get_rmse(output3)\n",
    "print(rmse3)\n",
    "rmse4 = get_rmse(output4)\n",
    "print(rmse4)\n",
    "# rmse1 = get_rmse(output1)\n",
    "# print(rmse1)\n",
    "# 1 remove difficulty\n",
    "# 2 remove price\n",
    "# 3 remove recipients\n",
    "# 4 remove num_tranc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/55\n",
      " - 23s - loss: 0.1814\n",
      "Epoch 2/55\n",
      " - 21s - loss: 0.1159\n",
      "Epoch 3/55\n",
      " - 21s - loss: 0.1081\n",
      "Epoch 4/55\n",
      " - 21s - loss: 0.0997\n",
      "Epoch 5/55\n",
      " - 21s - loss: 0.0953\n",
      "Epoch 6/55\n",
      " - 21s - loss: 0.0950\n",
      "Epoch 7/55\n",
      " - 21s - loss: 0.0919\n",
      "Epoch 8/55\n",
      " - 21s - loss: 0.0881\n",
      "Epoch 9/55\n",
      " - 21s - loss: 0.0883\n",
      "Epoch 10/55\n",
      " - 21s - loss: 0.0907\n",
      "Epoch 11/55\n",
      " - 24s - loss: 0.0869\n",
      "Epoch 12/55\n",
      " - 24s - loss: 0.0874\n",
      "Epoch 13/55\n",
      " - 24s - loss: 0.0842\n",
      "Epoch 14/55\n",
      " - 23s - loss: 0.0851\n",
      "Epoch 15/55\n",
      " - 23s - loss: 0.0897\n",
      "Epoch 16/55\n",
      " - 23s - loss: 0.0843\n",
      "Epoch 17/55\n",
      " - 22s - loss: 0.0840\n",
      "Epoch 18/55\n",
      " - 22s - loss: 0.0857\n",
      "Epoch 19/55\n",
      " - 22s - loss: 0.0842\n",
      "Epoch 20/55\n",
      " - 22s - loss: 0.0830\n",
      "Epoch 21/55\n",
      " - 22s - loss: 0.0790\n",
      "Epoch 22/55\n",
      " - 22s - loss: 0.0809\n",
      "Epoch 23/55\n",
      " - 24s - loss: 0.0809\n",
      "Epoch 24/55\n",
      " - 22s - loss: 0.0823\n",
      "Epoch 25/55\n",
      " - 22s - loss: 0.0764\n",
      "Epoch 26/55\n",
      " - 21s - loss: 0.0817\n",
      "Epoch 27/55\n",
      " - 21s - loss: 0.0830\n",
      "Epoch 28/55\n",
      " - 22s - loss: 0.0806\n",
      "Epoch 29/55\n",
      " - 22s - loss: 0.0822\n",
      "Epoch 30/55\n",
      " - 22s - loss: 0.0796\n",
      "Epoch 31/55\n",
      " - 27s - loss: 0.0817\n",
      "Epoch 32/55\n",
      " - 25s - loss: 0.0809\n",
      "Epoch 33/55\n",
      " - 24s - loss: 0.0808\n",
      "Epoch 34/55\n",
      " - 25s - loss: 0.0816\n",
      "Epoch 35/55\n",
      " - 25s - loss: 0.0830\n",
      "Epoch 36/55\n",
      " - 22s - loss: 0.0857\n",
      "Epoch 37/55\n",
      " - 21s - loss: 0.0810\n",
      "Epoch 38/55\n",
      " - 22s - loss: 0.0864\n",
      "Epoch 39/55\n",
      " - 23s - loss: 0.0803\n",
      "Epoch 40/55\n",
      " - 21s - loss: 0.0799\n",
      "Epoch 41/55\n",
      " - 21s - loss: 0.0805\n",
      "Epoch 42/55\n",
      " - 21s - loss: 0.0816\n",
      "Epoch 43/55\n",
      " - 21s - loss: 0.0816\n",
      "Epoch 44/55\n",
      " - 21s - loss: 0.0808\n",
      "Epoch 45/55\n",
      " - 23s - loss: 0.0809\n",
      "Epoch 46/55\n",
      " - 21s - loss: 0.0809\n",
      "Epoch 47/55\n",
      " - 23s - loss: 0.0800\n",
      "Epoch 48/55\n",
      " - 21s - loss: 0.0764\n",
      "Epoch 49/55\n",
      " - 22s - loss: 0.0779\n",
      "Epoch 50/55\n",
      " - 22s - loss: 0.0786\n",
      "Epoch 51/55\n",
      " - 22s - loss: 0.0768\n",
      "Epoch 52/55\n",
      " - 22s - loss: 0.0786\n",
      "Epoch 53/55\n",
      " - 22s - loss: 0.0811\n",
      "Epoch 54/55\n",
      " - 22s - loss: 0.0809\n",
      "Epoch 55/55\n",
      " - 22s - loss: 0.0830\n"
     ]
    }
   ],
   "source": [
    "eth_model_5 = build_model(inputs_5, output_size=1, neurons = 20)\n",
    "eth5_history = eth_model_5.fit(inputs_5, LSTM_training_outputs, \n",
    "                            epochs=55, batch_size=1,verbose=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "output5 = eth_model_5.predict(tinputs_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.316610956648462\n"
     ]
    }
   ],
   "source": [
    "rmse5 = get_rmse(output5)\n",
    "print(rmse5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
